# Multiagent-Prioritization

Multiagent-prioritization is a project designed to prioritize user stories generated by a GPT model. Users can either input content directly or upload a file to get user stories, which are then prioritized using various techniques. The prioritization process involves multi-agent discussions to prioritize the requirments. 
## Features

- **Content Input or File Upload**: Choose between direct content input or uploading a file to get user stories from the GPT model.
- **Single or Multi-Technique Prioritization**: Select single technique for prioritizing the user stories.
- **Multi-Agent Discussions**: Three agents discuss and decide on the prioritization technique(s) selected, providing a final prioritization table.

## Getting Started

### Prerequisites

- Python 3.7 or higher
- Starlette
- WebSockets
- Node.js 18.x or higher
- React 

### Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/yourusername/multiagent-prioritization.git OR the repo address 
    cd multiagent-prioritization
    ```

2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt or  pip install starlette uvicorn httpx python-dotenv streamlit python-multipart
    ```
3: NOTE: npm i to instal the packages, if you want to change in the front end, can use npm run build or can run live frontend server using npm run dev
   Can use dist folder 

## Empirical Datasets

The empirical datasets used in the Profes paper, which served as a foundation for this project, are available [here](https://github.com/GPT-Laboratory/multiagent-prioritization/tree/main/Datasets_And_results). These datasets are crucial for testing and validating the prioritization techniques implemented in this project.

## Llama 3 Integration

For Llama 3 model integration, we utilize GroqCloud. Detailed instructions for getting started with GroqCloud can be found in the [GroqCloud Quickstart Guide](https://console.groq.com/docs/quickstart).

## Create .env file and placed in root directory 

### Write your OPENAI API's key minimum 3 and 2 groqcloud api, to avoid API error for multi async calls.
```bash
API-KEY1=YOUR_API_KEY 1  
API-KEY2=YOUR_API_KEY 2
API-KEY3YOUR_API_KEY 3
LLAMA-key1=
LLAMA-key2=
```

Must add this env file in the .gitignore file before pushing the code in your repository


### Usage

1. Start the Starlette server:
    ```bash
    uvicorn app:app --reload
    ```

2. Open your browser and navigate to `http://127.0.0.1:8000`.

### User Flow

#### Step 1: Select Input Type

- **Content Input**: Directly enter the content for generating user stories.
- **Upload File**: Upload a file containing the content for generating user stories.

#### Step 2: Select Prioritization Method

After receiving the user stories, select the prioritization method:

- **Single Technique Prioritization**: Choose one technique for prioritization.
  - Three agents will discuss the chosen technique.
  - After the discussion, the final prioritization table is displayed.


### API Endpoints

- `POST /generate`: Generate user stories from input content or uploaded file.
- `POST /prioritize`: Prioritize the generated user stories using the selected technique(s).

### WebSockets

WebSockets are used to facilitate real-time communication between the client and the server, enabling multi-agent discussions and live updates of the prioritization process.

The CSV file is attached to upload and test it. 
[backlog_requirements_with_ai.csv](https://github.com/user-attachments/files/15751077/backlog_requirements_with_ai.csv)

Architecture and Results 
<table>
  <tr>
    <td><img src="https://github.com/GPT-Laboratory/multiagent-prioritization/raw/main/Datasets_And_results/Architecture.jpeg" alt="Architecture Diagram" width="400"/></td>
    <td><img src="https://github.com/GPT-Laboratory/multiagent-prioritization/raw/main/Datasets_And_results/all4ProjectStoriesResults.png" alt="Project Stories Results" width="400"/></td>
  </tr>
</table>


## Demo Video

[![Watch the video](https://img.youtube.com/vi/CIKOFt-Vr1k/maxresdefault.jpg)](https://youtu.be/CIKOFt-Vr1k)




